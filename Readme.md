# Go Distributed Task Queue (Golang + Redis)

A productionâ€‘style task queue built in Go with Redis, worker pool, retries with exponential backoff, a Deadâ€‘Letter Queue (DLQ), Prometheus metrics, Grafana dashboards, and a minimal Admin UI.

> **Why this project?**
> Demonstrates practical distributedâ€‘systems skills: durability, concurrency, observability, faultâ€‘tolerance, and operability.

---

## âœ¨ Features

* **Redisâ€‘backed queue** (LPUSH/BRPOP) â€“ works across processes/hosts
* **Worker pool** with perâ€‘job timeout
* **Retries** with **exponential backoff**
* **Deadâ€‘Letter Queue (DLQ)** for permanently failing jobs
* **Job status & history** in Redis (quick lookups + debugging)
* **Prometheus metrics** at `/metrics`
* **Grafana dashboard** (custom panels for queue health)
* **Admin UI** (readâ€‘only list + DLQ actions: retry/delete)

---

## ğŸ— Architecture

```mermaid
flowchart LR
    C[Client / Producer] -->|HTTP /enqueue| API[Go HTTP API]
    subgraph App[Go Service]
      API -->|LPUSH job JSON| RQ[(Redis List: job_queue)]
      W1[Worker 1]
      W2[Worker 2]
      W3[Worker N]
      W1 & W2 & W3 -->|BRPOP job_queue| RQ
      W1 & W2 & W3 -->|Process + timeout + retry| Logic[Retry & Backoff]
      Logic -->|on fail & retries left| RQ
      Logic -->|on final fail| DLQ[(Redis List: dead_letter_queue)]
      API --> Status[(Redis: job_status:<id>)]
      API --> JH[(Redis: job:<id> & job_history)]
      Admin[Admin UI /admin] --> API
      Metrics[/Prometheus /metrics/] --> API
    end
    Prom[Prometheus] -->|scrape /metrics| Metrics
    Graf[Grafana] -->|query| Prom
```

**Queues & Keys**

* `job_queue` â€“ main FIFO/LIFO list (LPUSH + BRPOP)
* `dead_letter_queue` â€“ permanently failed jobs
* `job_status:<id>` â€“ string status (`QUEUED/PROCESSING/RETRYING/SUCCESS/FAILED`)
* `job:<id>` â€“ hash for job metadata; `job_history` â€“ list of finished job IDs

---

## ğŸ“¦ Project Layout (suggested)

```
.
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ main.go                # HTTP server, route wiring
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ queue/
â”‚   â”‚   â”œâ”€â”€ queue.go           # job model, inâ€‘mem queue, worker pool
â”‚   â”‚   â””â”€â”€ redis_queue.go     # Redis client, enqueue/dequeue, DLQ
â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â””â”€â”€ metrics.go         # Prometheus registry & metrics
â”‚   â””â”€â”€ http/
â”‚       â””â”€â”€ admin.go           # Admin UI routes & template
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ docker-compose.yml     # Prometheus + Grafana stack
â”‚   â””â”€â”€ prometheus.yml         # Prometheus scrape config
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start (local)

### 1) Start Redis

```bash
# Mac (brew)
brew install redis && redis-server
# Linux
docker run -p 6379:6379 redis:7-alpine
```

### 2) Run Go service

```bash
go run ./cmd/main.go
```

### 3) Enqueue a few jobs

```bash
curl "http://localhost:8080/enqueue?name=VideoEncode"
curl "http://localhost:8080/enqueue?name=EmailSend"
```

### 4) Check status / history

```bash
curl "http://localhost:8080/status?id=1"
curl "http://localhost:8080/history"
```

### 5) Admin UI

Open: `http://localhost:8080/admin`

---

## ğŸ“ˆ Metrics & Monitoring

### Prometheus endpoint

* Exposed at: `http://localhost:8080/metrics`
* **Custom metrics**

  * `taskqueue_jobs_enqueued_total` (counter)
  * `taskqueue_jobs_completed_total` (counter)
  * `taskqueue_jobs_failed_total` (counter)
  * `taskqueue_job_processing_duration_seconds` (histogram)
  * `taskqueue_job_processing_duration_seconds_latest` (gauge)
  * `taskqueue_job_processing_duration_seconds_average` (gauge)
  * `taskqueue_queue_depth` (gauge)
  * `taskqueue_dlq_size` (gauge)

### Useful PromQL snippets

```promql
# p50 processing time (histogram)
histogram_quantile(0.5, sum(rate(taskqueue_job_processing_duration_seconds_bucket[2m])) by (le))

# enqueue vs completed (perâ€‘minute rate)
rate(taskqueue_jobs_enqueued_total[1m])
rate(taskqueue_jobs_completed_total[1m])

# failures (perâ€‘5m)
increase(taskqueue_jobs_failed_total[5m])
```

### Run Prometheus + Grafana via Docker Compose

From `monitoring/`:

```bash
docker compose up -d
```

* Prometheus: [http://localhost:9090](http://localhost:9090)
* Grafana: [http://localhost:3000](http://localhost:3000) (admin / admin)
* In Grafana â†’ **Connections â†’ Data Sources** â†’ add Prometheus with URL `http://prometheus:9090`.
* Create panels using the metrics above (e.g., *Jobs Enqueued*, *Jobs Completed*, *Queue Depth*, *Job Processing Time (Latest/Avg)*).

> If your Go service runs on host, use `host.docker.internal:8080` (Mac/Win) or `172.17.0.1:8080` (Linux) as Prometheus target in `prometheus.yml`.

---

## âš™ï¸ Behavior & Key Design Choices

### Worker execution and timeouts

* Each job runs with a timeout; long jobs are marked failed and retried or sent to DLQ.

### Retries with exponential backoff

* On failure: delay grows like `base * 2^retries` to avoid retry storms.

### Deadâ€‘Letter Queue (DLQ)

* When retries exceed `MaxRetry`, job is pushed to `dead_letter_queue`.
* Admin UI exposes **Retry** (resets retries to 0) and **Delete** actions.

### Status & history

* Fast lookups via `job_status:<id>` strings.
* Metadata persisted in `job:<id>` hash; finished IDs appended to `job_history`.

---

## ğŸ”§ Configuration (env vars you can add)

* `REDIS_ADDR` (default `localhost:6379`)
* `WORKER_COUNT` (default `3`)
* `JOB_TIMEOUT_SECONDS` (default `3`)
* `MAX_RETRY` (default `3`)
* `BACKOFF_BASE_SECONDS` (default `5`)

*(In code, read via `os.Getenv` with sensible fallbacks.)*

---

## ğŸ›  API Endpoints

* `POST /enqueue?name=...` â†’ create a job
* `GET  /status?id=<id>` â†’ job status
* `GET  /history` â†’ recent finished jobs
* `GET  /admin` â†’ admin dashboard (HTML)
* `POST /dlq/retry?id=<id>` â†’ move job from DLQ to queue
* `POST /dlq/delete?id=<id>` â†’ remove job from DLQ
* `GET  /metrics` â†’ Prometheus metrics

---

## ğŸ§ª How To Demo (script)

1. Enqueue 5â€“10 jobs (some will randomly fail):

   ```bash
   for i in {1..10}; do curl -s "http://localhost:8080/enqueue?name=Demo-$i"; done
   ```
2. Open `/admin` â†’ see **Recent Jobs** and **DLQ** filling up.
3. In Grafana, watch panels:

   * *Jobs Enqueued/Completed*
   * *Queue Depth*
   * *Job Processing Time (Latest/Avg)*
4. Click **Retry** on some DLQ jobs â†’ watch them reâ€‘enter the queue.

---

## ğŸ§  Scaling & Operations

* **Horizontal scaling**: run more replicas of the Go service; all share Redis.
* **Autoscaling signal**: sustained `taskqueue_queue_depth` > threshold.
* **Graceful shutdown**: drain workers before stopping (add signal handling).
* **Observability**: alert on rising failures, growing DLQ, high p99 latency.

---

## ğŸ“¸ Screenshots (add to repo)

* `docs/grafana-dashboard.png` â€“ key panels
* `docs/admin-ui.png` â€“ Admin page

Embed them here once captured:

```md
![Grafana](docs/grafana-dashboard.png)
![Admin UI](docs/admin-ui.png)
```

---

## ğŸ—º Roadmap / Niceâ€‘toâ€‘haves

* Perâ€‘jobâ€‘type handlers (plugin registry)
* Priority queues (separate Redis lists)
* Scheduled jobs (delayed delivery bucket)
* Graceful shutdown & inâ€‘flight job requeue
* Persistent job results storage
* Auth for Admin UI

---

## ğŸ™Œ Credits

Built by Devang to demonstrate Go concurrency, Redis, and production observability practices.
